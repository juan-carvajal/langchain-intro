{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are LLMs?\n",
    "\n",
    "## Language Models (LMs)\n",
    "Language Models are AI models that are designed to understand and generate human-like text. They are trained on large amounts of text data to learn patterns, relationships, and probabilities of word sequences in order to generate coherent and contextually relevant text. LMs can be used for a wide range of natural language processing tasks such as text generation, summarization, translation, and question answering.\n",
    "\n",
    "## Large Language Models (LLMs)\n",
    "Large Language Models (LLMs) refer to advanced language models like GPT-3, developed by OpenAI. These models are characterized by their massive size, typically consisting of billions of parameters. LLMs are trained on extensive datasets from the internet and other sources, allowing them to capture a wide range of linguistic patterns and semantic relationships.\n",
    "\n",
    "## Key Benefits of LLMs\n",
    "- Improved Text Quality: LLMs have demonstrated remarkable text generation capabilities, producing human-like and contextually coherent responses. They can understand complex queries and generate detailed and relevant responses.\n",
    "\n",
    "- Broad Applicability: LLMs can be fine-tuned or adapted for specific tasks, making them versatile across various domains. They have been used for content generation, customer service, virtual assistants, and even creative writing.\n",
    "\n",
    "- Knowledge Comprehension: LLMs can understand and utilize vast amounts of knowledge acquired during training. They can provide information, answer questions, and generate text on a wide range of topics, enhancing their utility as information resources.\n",
    "\n",
    "## Caveats of LLMs\n",
    "- Lack of Factual Accuracy: LLMs may generate responses that sound plausible but are factually incorrect. They cannot verify the accuracy of information or distinguish between reliable and unreliable sources. Care should be taken when using LLMs for critical or sensitive information.\n",
    "\n",
    "- Bias and Ethical Considerations: LLMs can inadvertently reflect and amplify biases present in the training data. They may produce biased or inappropriate content if not carefully monitored and fine-tuned. Efforts are being made to address these concerns and ensure responsible use of LLMs.\n",
    "\n",
    "- Resource-Intensive: LLMs require significant computational resources, including powerful hardware and energy consumption, for both training and deployment. This can limit their accessibility and scalability for certain applications.\n",
    "\n",
    "- Abstract interfaces: Given their exclusive string inputs, LLMs are easy to interface with existing technology, but there is no clear prompt format or strategy that will guarantee deterministic and clear results.\n",
    "\n",
    "- Non-determinism\n",
    "\n",
    "Overall, LLMs offer tremendous potential for generating high-quality text and understanding human language, but their deployment and usage should be accompanied by ethical considerations and careful scrutiny to ensure responsible and accurate outputs.\n",
    "\n",
    "# [Langchain](https://python.langchain.com/en/latest/index.html)\n",
    "\n",
    "> **LangChain**  is a framework for developing applications powered by language models. We believe that the most powerful and differentiated\n",
    "> applications will not only call out to a language model, but will also\n",
    "> be:\n",
    "> \n",
    "> 1.  _Data-aware_: connect a language model to other sources of data\n",
    ">     \n",
    "> 2.  _Agentic_: allow a language model to interact with its environment\n",
    ">     \n",
    "> \n",
    "> The LangChain framework is designed around these principles.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dotenv\n",
    "Required environment variables:\n",
    "- OPENAI_API_KEY: API key to access Open AI LLMs\n",
    "- SERPAPI_API_KEY: API key to access Google search Python API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load env variables\n",
    "# OPENAI_API_KEY=...\n",
    "# SERPAPI_API_KEY=...\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic example\n",
    "How to ask something to an LLM?\n",
    "## Model \"Temperature\"\n",
    "LLMs are non-deterministic by nature. OpenAI models incorporates a parameter to configure the level of determinism. 0 means the lowest level of \"creativity\", so answers will be more plain and tend to be the same each time. 1 is maximum \"creativity\". It is to be noted that using a value of 0 does not guarantee non-determinism, as this is part of the nature of LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "EPAM Systems is an IT services provider headquartered in Newtown, Pennsylvania, USA. It is one of the largest IT services companies in Central and Eastern Europe, offering software product development, engineering, business consulting, software engineering, and customer support services. The company has been in business since 1993 and employs more than 32,000 people across the globe. EPAM is listed on the New York Stock Exchange and has been recognized as a leader in many industry categories, such as being listed in Gartner's Magic Quadrant for Application and Software Testing Services, and being listed as a Top 10 global IT services vendor by Forbes. EPAM recently made the Transition 100 list of the top emerging companies to watch.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(temperature=0.9)\n",
    "text = \"What do you know about EPAM Systems?\"\n",
    "print(llm(text))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What do you know about EPAM Systems?\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"company\"],\n",
    "    template=\"What do you know about {company}?\",\n",
    ")\n",
    "print(prompt.format(company=\"EPAM Systems\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLMChains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = OpenAI(temperature=0.9)\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"company\"],\n",
    "    template=\"What do you know about {company}?\",\n",
    ")\n",
    "chain = LLMChain(llm=llm, prompt=prompt, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWhat do you know about EPAM Systems?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\nEPAM Systems is an American-based, global provider of software product engineering and digital platform engineering services. Founded in 1993, EPAM has over 33,000 employees across 25 countries. EPAM's services include software product development, digital platform engineering, enterprise engineering, cloud engineering, and customer experience design. EPAM's clients include leading organizations such as Microsoft, Cisco, Adobe, and Dell.\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"EPAM Systems\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents (basic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# First, let's load the language model we're going to use to control the agent.\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "# Next, let's load some tools to use. Note that the `llm-math` tool uses an LLM, so we need to pass that in.\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
    "\n",
    "\n",
    "# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True, max_execution_time=10, early_stopping_method=\"generate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find the temperature first, then use the calculator to raise it to the .023 power.\n",
      "Action: Search\n",
      "Action Input: \"High temperature in SF yesterday\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mHigh: 64.94ºf @1:56 PM Low: 53.6ºf @5:00 AM Approx.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to convert the temperature to a number\n",
      "Action: Calculator\n",
      "Action Input: 64.94\u001b[0m"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "unknown format from LLM: This is not a math problem and cannot be solved using the numexpr library.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Now let's test it out!\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m agent\u001b[39m.\u001b[39;49mrun(\u001b[39m\"\u001b[39;49m\u001b[39mWhat was the high temperature in SF yesterday in Fahrenheit? What is that number raised to the .023 power?\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/Projects/epam/python/langchain/env/lib/python3.10/site-packages/langchain/chains/base.py:236\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, *args, **kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    235\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`run` supports only one positional argument.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 236\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(args[\u001b[39m0\u001b[39;49m], callbacks\u001b[39m=\u001b[39;49mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n\u001b[1;32m    238\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m    239\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(kwargs, callbacks\u001b[39m=\u001b[39mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n",
      "File \u001b[0;32m~/Projects/epam/python/langchain/env/lib/python3.10/site-packages/langchain/chains/base.py:140\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 140\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    141\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    142\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001b[0;32m~/Projects/epam/python/langchain/env/lib/python3.10/site-packages/langchain/chains/base.py:134\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[1;32m    128\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    129\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[1;32m    130\u001b[0m     inputs,\n\u001b[1;32m    131\u001b[0m )\n\u001b[1;32m    132\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 134\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    135\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    136\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    137\u001b[0m     )\n\u001b[1;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/Projects/epam/python/langchain/env/lib/python3.10/site-packages/langchain/agents/agent.py:951\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[39m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[1;32m    950\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[0;32m--> 951\u001b[0m     next_step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_take_next_step(\n\u001b[1;32m    952\u001b[0m         name_to_tool_map,\n\u001b[1;32m    953\u001b[0m         color_mapping,\n\u001b[1;32m    954\u001b[0m         inputs,\n\u001b[1;32m    955\u001b[0m         intermediate_steps,\n\u001b[1;32m    956\u001b[0m         run_manager\u001b[39m=\u001b[39;49mrun_manager,\n\u001b[1;32m    957\u001b[0m     )\n\u001b[1;32m    958\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[1;32m    959\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_return(\n\u001b[1;32m    960\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[39m=\u001b[39mrun_manager\n\u001b[1;32m    961\u001b[0m         )\n",
      "File \u001b[0;32m~/Projects/epam/python/langchain/env/lib/python3.10/site-packages/langchain/agents/agent.py:818\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m    816\u001b[0m         tool_run_kwargs[\u001b[39m\"\u001b[39m\u001b[39mllm_prefix\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m     \u001b[39m# We then call the tool on the tool input to get an observation\u001b[39;00m\n\u001b[0;32m--> 818\u001b[0m     observation \u001b[39m=\u001b[39m tool\u001b[39m.\u001b[39;49mrun(\n\u001b[1;32m    819\u001b[0m         agent_action\u001b[39m.\u001b[39;49mtool_input,\n\u001b[1;32m    820\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    821\u001b[0m         color\u001b[39m=\u001b[39;49mcolor,\n\u001b[1;32m    822\u001b[0m         callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child() \u001b[39mif\u001b[39;49;00m run_manager \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    823\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtool_run_kwargs,\n\u001b[1;32m    824\u001b[0m     )\n\u001b[1;32m    825\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    826\u001b[0m     tool_run_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent\u001b[39m.\u001b[39mtool_run_logging_kwargs()\n",
      "File \u001b[0;32m~/Projects/epam/python/langchain/env/lib/python3.10/site-packages/langchain/tools/base.py:255\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mException\u001b[39;00m, \u001b[39mKeyboardInterrupt\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    254\u001b[0m     run_manager\u001b[39m.\u001b[39mon_tool_error(e)\n\u001b[0;32m--> 255\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    256\u001b[0m run_manager\u001b[39m.\u001b[39mon_tool_end(\u001b[39mstr\u001b[39m(observation), color\u001b[39m=\u001b[39mcolor, name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    257\u001b[0m \u001b[39mreturn\u001b[39;00m observation\n",
      "File \u001b[0;32m~/Projects/epam/python/langchain/env/lib/python3.10/site-packages/langchain/tools/base.py:249\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    247\u001b[0m     tool_args, tool_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_to_args_and_kwargs(parsed_input)\n\u001b[1;32m    248\u001b[0m     observation \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 249\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(\u001b[39m*\u001b[39;49mtool_args, run_manager\u001b[39m=\u001b[39;49mrun_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtool_kwargs)\n\u001b[1;32m    250\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    251\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run(\u001b[39m*\u001b[39mtool_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtool_kwargs)\n\u001b[1;32m    252\u001b[0m     )\n\u001b[1;32m    253\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mException\u001b[39;00m, \u001b[39mKeyboardInterrupt\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    254\u001b[0m     run_manager\u001b[39m.\u001b[39mon_tool_error(e)\n",
      "File \u001b[0;32m~/Projects/epam/python/langchain/env/lib/python3.10/site-packages/langchain/tools/base.py:344\u001b[0m, in \u001b[0;36mTool._run\u001b[0;34m(self, run_manager, *args, **kwargs)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Use the tool.\"\"\"\u001b[39;00m\n\u001b[1;32m    342\u001b[0m new_argument_supported \u001b[39m=\u001b[39m signature(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc)\u001b[39m.\u001b[39mparameters\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 344\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(\n\u001b[1;32m    345\u001b[0m         \u001b[39m*\u001b[39;49margs,\n\u001b[1;32m    346\u001b[0m         callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child() \u001b[39mif\u001b[39;49;00m run_manager \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    347\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    348\u001b[0m     )\n\u001b[1;32m    349\u001b[0m     \u001b[39mif\u001b[39;00m new_argument_supported\n\u001b[1;32m    350\u001b[0m     \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    351\u001b[0m )\n",
      "File \u001b[0;32m~/Projects/epam/python/langchain/env/lib/python3.10/site-packages/langchain/chains/base.py:236\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, *args, **kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    235\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`run` supports only one positional argument.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 236\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(args[\u001b[39m0\u001b[39;49m], callbacks\u001b[39m=\u001b[39;49mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n\u001b[1;32m    238\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m    239\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(kwargs, callbacks\u001b[39m=\u001b[39mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n",
      "File \u001b[0;32m~/Projects/epam/python/langchain/env/lib/python3.10/site-packages/langchain/chains/base.py:140\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 140\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    141\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    142\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001b[0;32m~/Projects/epam/python/langchain/env/lib/python3.10/site-packages/langchain/chains/base.py:134\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[1;32m    128\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    129\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[1;32m    130\u001b[0m     inputs,\n\u001b[1;32m    131\u001b[0m )\n\u001b[1;32m    132\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 134\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    135\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    136\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    137\u001b[0m     )\n\u001b[1;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/Projects/epam/python/langchain/env/lib/python3.10/site-packages/langchain/chains/llm_math/base.py:149\u001b[0m, in \u001b[0;36mLLMMathChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    143\u001b[0m _run_manager\u001b[39m.\u001b[39mon_text(inputs[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_key])\n\u001b[1;32m    144\u001b[0m llm_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm_chain\u001b[39m.\u001b[39mpredict(\n\u001b[1;32m    145\u001b[0m     question\u001b[39m=\u001b[39minputs[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_key],\n\u001b[1;32m    146\u001b[0m     stop\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39m```output\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m    147\u001b[0m     callbacks\u001b[39m=\u001b[39m_run_manager\u001b[39m.\u001b[39mget_child(),\n\u001b[1;32m    148\u001b[0m )\n\u001b[0;32m--> 149\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_llm_result(llm_output, _run_manager)\n",
      "File \u001b[0;32m~/Projects/epam/python/langchain/env/lib/python3.10/site-packages/langchain/chains/llm_math/base.py:112\u001b[0m, in \u001b[0;36mLLMMathChain._process_llm_result\u001b[0;34m(self, llm_output, run_manager)\u001b[0m\n\u001b[1;32m    110\u001b[0m     answer \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mAnswer: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m llm_output\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39mAnswer:\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m    111\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 112\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munknown format from LLM: \u001b[39m\u001b[39m{\u001b[39;00mllm_output\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    113\u001b[0m \u001b[39mreturn\u001b[39;00m {\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key: answer}\n",
      "\u001b[0;31mValueError\u001b[0m: unknown format from LLM: This is not a math problem and cannot be solved using the numexpr library."
     ]
    }
   ],
   "source": [
    "# Now let's test it out!\n",
    "agent.run(\"What was the high temperature in SF yesterday in Fahrenheit? What is that number raised to the .023 power?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConversationChains\n",
    "Conversation models with memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi there!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " Hi there! It's nice to meet you. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "from langchain import OpenAI, ConversationChain\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "conversation = ConversationChain(llm=llm, verbose=True)\n",
    "\n",
    "output = conversation.predict(input=\"Hi there!\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: I'm doing well! Just having a conversation with an AI.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " That's great! It's always nice to have a conversation with someone new. What would you like to talk about?\n"
     ]
    }
   ],
   "source": [
    "output = conversation.predict(input=\"I'm doing well! Just having a conversation with an AI.\")\n",
    "print(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular LLMs vs Chat models\n",
    "The Langchain framework has a distinctive way of differentiating regular text models from chat-optimized models.\n",
    "The `OpenAI` constructor will use the `text-davinci-003` model, while `ChatOpenAI` will use `gpt-3.5-turbo`.\n",
    "\n",
    "[Here](https://platform.openai.com/docs/models/overview) you can find more information on the different LLMs that are supported by the Open AI platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'aime programmer.\", additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import (\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "\n",
    "chat = ChatOpenAI(temperature=0)\n",
    "\n",
    "chat([HumanMessage(content=\"Translate this sentence from English to French. I love programming.\")])\n",
    "# -> AIMessage(content=\"J'aime programmer.\", additional_kwargs={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResult(generations=[[ChatGeneration(text=\"J'adore la programmation.\", generation_info=None, message=AIMessage(content=\"J'adore la programmation.\", additional_kwargs={}, example=False))], [ChatGeneration(text=\"J'adore l'intelligence artificielle.\", generation_info=None, message=AIMessage(content=\"J'adore l'intelligence artificielle.\", additional_kwargs={}, example=False))]], llm_output={'token_usage': {'prompt_tokens': 57, 'completion_tokens': 20, 'total_tokens': 77}, 'model_name': 'gpt-3.5-turbo'})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_messages = [\n",
    "    [\n",
    "        SystemMessage(content=\"You are a helpful assistant that translates English to French.\"),\n",
    "        HumanMessage(content=\"I love programming.\")\n",
    "    ],\n",
    "    [\n",
    "        SystemMessage(content=\"You are a helpful assistant that translates English to French.\"),\n",
    "        HumanMessage(content=\"I love artificial intelligence.\")\n",
    "    ],\n",
    "]\n",
    "result = chat.generate(batch_messages)\n",
    "result\n",
    "# -> LLMResult(generations=[[ChatGeneration(text=\"J'aime programmer.\", generation_info=None, message=AIMessage(content=\"J'aime programmer.\", additional_kwargs={}))], [ChatGeneration(text=\"J'aime l'intelligence artificielle.\", generation_info=None, message=AIMessage(content=\"J'aime l'intelligence artificielle.\", additional_kwargs={}))]], llm_output={'token_usage': {'prompt_tokens': 57, 'completion_tokens': 20, 'total_tokens': 77}})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Agents\n",
    "LLM agents are the composition of LLMs, prompt strategies and different tools to respond to complicated tasks in an autonomous way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "ename": "OutputParserException",
     "evalue": "Could not parse LLM output: Thought: I need to use the search tool to find the current price of EPAM in NYSE and then use the calculator tool to raise it to the 0.23 power.\n\nAction:\n```\n{\n  \"action\": \"Search\",\n  \"action_input\": \"EPAM NYSE price\"\n}\n```\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/Projects/epam/python/langchain/env/lib/python3.10/site-packages/langchain/agents/chat/output_parser.py:21\u001b[0m, in \u001b[0;36mChatOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 21\u001b[0m     response \u001b[39m=\u001b[39m parse_json_markdown(text)\n\u001b[1;32m     22\u001b[0m     \u001b[39mreturn\u001b[39;00m AgentAction(response[\u001b[39m\"\u001b[39m\u001b[39maction\u001b[39m\u001b[39m\"\u001b[39m], response[\u001b[39m\"\u001b[39m\u001b[39maction_input\u001b[39m\u001b[39m\"\u001b[39m], text)\n",
      "File \u001b[0;32m~/Projects/epam/python/langchain/env/lib/python3.10/site-packages/langchain/output_parsers/json.py:17\u001b[0m, in \u001b[0;36mparse_json_markdown\u001b[0;34m(json_string)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39m# Parse the JSON string into a Python dictionary\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m parsed \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39;49mloads(json_string)\n\u001b[1;32m     19\u001b[0m \u001b[39mreturn\u001b[39;00m parsed\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.11/Frameworks/Python.framework/Versions/3.10/lib/python3.10/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_decoder\u001b[39m.\u001b[39;49mdecode(s)\n\u001b[1;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.11/Frameworks/Python.framework/Versions/3.10/lib/python3.10/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[39mcontaining a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_decode(s, idx\u001b[39m=\u001b[39;49m_w(s, \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mend())\n\u001b[1;32m    338\u001b[0m end \u001b[39m=\u001b[39m _w(s, end)\u001b[39m.\u001b[39mend()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.11/Frameworks/Python.framework/Versions/3.10/lib/python3.10/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[39mraise\u001b[39;00m JSONDecodeError(\u001b[39m\"\u001b[39m\u001b[39mExpecting value\u001b[39m\u001b[39m\"\u001b[39m, s, err\u001b[39m.\u001b[39mvalue) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[39mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m agent \u001b[39m=\u001b[39m initialize_agent(tools, chat, agent\u001b[39m=\u001b[39mAgentType\u001b[39m.\u001b[39mCHAT_ZERO_SHOT_REACT_DESCRIPTION, verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     18\u001b[0m \u001b[39m# Now let's test it out!\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m agent\u001b[39m.\u001b[39;49mrun(\u001b[39m\"\u001b[39;49m\u001b[39mWhat is EPAM price in NYSE? What is that number raised to the 0.23 power?\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/Projects/epam/python/langchain/env/lib/python3.10/site-packages/langchain/chains/base.py:236\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, *args, **kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    235\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`run` supports only one positional argument.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 236\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(args[\u001b[39m0\u001b[39;49m], callbacks\u001b[39m=\u001b[39;49mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n\u001b[1;32m    238\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m    239\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(kwargs, callbacks\u001b[39m=\u001b[39mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n",
      "File \u001b[0;32m~/Projects/epam/python/langchain/env/lib/python3.10/site-packages/langchain/chains/base.py:140\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 140\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    141\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    142\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001b[0;32m~/Projects/epam/python/langchain/env/lib/python3.10/site-packages/langchain/chains/base.py:134\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[1;32m    128\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    129\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[1;32m    130\u001b[0m     inputs,\n\u001b[1;32m    131\u001b[0m )\n\u001b[1;32m    132\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 134\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    135\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    136\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    137\u001b[0m     )\n\u001b[1;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/Projects/epam/python/langchain/env/lib/python3.10/site-packages/langchain/agents/agent.py:951\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[39m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[1;32m    950\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[0;32m--> 951\u001b[0m     next_step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_take_next_step(\n\u001b[1;32m    952\u001b[0m         name_to_tool_map,\n\u001b[1;32m    953\u001b[0m         color_mapping,\n\u001b[1;32m    954\u001b[0m         inputs,\n\u001b[1;32m    955\u001b[0m         intermediate_steps,\n\u001b[1;32m    956\u001b[0m         run_manager\u001b[39m=\u001b[39;49mrun_manager,\n\u001b[1;32m    957\u001b[0m     )\n\u001b[1;32m    958\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[1;32m    959\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_return(\n\u001b[1;32m    960\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[39m=\u001b[39mrun_manager\n\u001b[1;32m    961\u001b[0m         )\n",
      "File \u001b[0;32m~/Projects/epam/python/langchain/env/lib/python3.10/site-packages/langchain/agents/agent.py:773\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m    771\u001b[0m     raise_error \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[39mif\u001b[39;00m raise_error:\n\u001b[0;32m--> 773\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    774\u001b[0m text \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(e)\n\u001b[1;32m    775\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_parsing_errors, \u001b[39mbool\u001b[39m):\n",
      "File \u001b[0;32m~/Projects/epam/python/langchain/env/lib/python3.10/site-packages/langchain/agents/agent.py:762\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Take a single step in the thought-action-observation loop.\u001b[39;00m\n\u001b[1;32m    757\u001b[0m \n\u001b[1;32m    758\u001b[0m \u001b[39mOverride this to take control of how the agent makes and acts on choices.\u001b[39;00m\n\u001b[1;32m    759\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    760\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    761\u001b[0m     \u001b[39m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[0;32m--> 762\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49magent\u001b[39m.\u001b[39;49mplan(\n\u001b[1;32m    763\u001b[0m         intermediate_steps,\n\u001b[1;32m    764\u001b[0m         callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child() \u001b[39mif\u001b[39;49;00m run_manager \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    765\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs,\n\u001b[1;32m    766\u001b[0m     )\n\u001b[1;32m    767\u001b[0m \u001b[39mexcept\u001b[39;00m OutputParserException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    768\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_parsing_errors, \u001b[39mbool\u001b[39m):\n",
      "File \u001b[0;32m~/Projects/epam/python/langchain/env/lib/python3.10/site-packages/langchain/agents/agent.py:444\u001b[0m, in \u001b[0;36mAgent.plan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    442\u001b[0m full_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_full_inputs(intermediate_steps, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    443\u001b[0m full_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm_chain\u001b[39m.\u001b[39mpredict(callbacks\u001b[39m=\u001b[39mcallbacks, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfull_inputs)\n\u001b[0;32m--> 444\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput_parser\u001b[39m.\u001b[39;49mparse(full_output)\n",
      "File \u001b[0;32m~/Projects/epam/python/langchain/env/lib/python3.10/site-packages/langchain/agents/chat/output_parser.py:25\u001b[0m, in \u001b[0;36mChatOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[39mreturn\u001b[39;00m AgentAction(response[\u001b[39m\"\u001b[39m\u001b[39maction\u001b[39m\u001b[39m\"\u001b[39m], response[\u001b[39m\"\u001b[39m\u001b[39maction_input\u001b[39m\u001b[39m\"\u001b[39m], text)\n\u001b[1;32m     24\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m     \u001b[39mraise\u001b[39;00m OutputParserException(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not parse LLM output: \u001b[39m\u001b[39m{\u001b[39;00mtext\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mOutputParserException\u001b[0m: Could not parse LLM output: Thought: I need to use the search tool to find the current price of EPAM in NYSE and then use the calculator tool to raise it to the 0.23 power.\n\nAction:\n```\n{\n  \"action\": \"Search\",\n  \"action_input\": \"EPAM NYSE price\"\n}\n```\n\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# First, let's load the language model we're going to use to control the agent.\n",
    "chat = ChatOpenAI(temperature=0)\n",
    "\n",
    "# Next, let's load some tools to use. Note that the `llm-math` tool uses an LLM, so we need to pass that in.\n",
    "llm = OpenAI(temperature=0)\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
    "\n",
    "\n",
    "# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.\n",
    "agent = initialize_agent(tools, chat, agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "\n",
    "# Now let's test it out!\n",
    "agent.run(\"What is EPAM price in NYSE? What is that number raised to the 0.23 power?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Opened issue](https://github.com/hwchase17/langchain/issues/5299)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Agent toolkits - using JSON, CSV, etc.](https://python.langchain.com/en/latest/modules/agents/toolkits.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: json_spec_list_keys\n",
      "Action Input: data\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m['items']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should look at the items to see what I can find\n",
      "Action: json_spec_list_keys\n",
      "Action Input: data[\"items\"]\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mValueError('Value at path `data[\"items\"]` is not a dict, get the value directly.')\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should get the value of items\n",
      "Action: json_spec_get_value\n",
      "Action Input: data[\"items\"]\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m[{'product_id': 1, 'product_name': 'Lunes - Creamy garlic chicken breast', 'product_category': 'N0eOoycGSiKTYzGgn2y6', 'description': '150 grs. de pechuga de pollo apanada en salsa cremosa de ajo, gratinada con tocineta, acompañada de ensalada verde.', 'price': 15000, 'options': [], 'recommended': False, 'order': 1}, {'product_id': 2, 'product_name': 'Martes - Lemon butter chicken', 'product_category': 'N0eOoycGSiKTYzGgn2y6', 'description': '250 grs. de pechuga de pollo al horno bañada en mantequilla y limón, acompañado de puré y ensalada verde.', 'price': 15000, 'options': [], 'recommended': False, 'order': 2}, {'product_id': 3, 'product_name': 'Miercoles - Cajún-chicken sandwich', 'product_category': 'N0eOoycGSiKTYzGgn2y6', 'description': 'sandwich de pechuga de pollo, lechuga, tomate y mayonesa de cajún, acompañado de ensalada cole slaw.', 'price': 15000, 'options': [], 'recommended': False, 'order': 3}, {'product_id': 4, 'product_name': 'Jueves - Pulled-pork sandwich', 'product_category': 'N0eOoycGSiKTYzGgn2y6', 'description': 'sandwich de carne desmechada de cerdo en salsa BBQ, cole slaw y pepinillos, acompañado de ensalada cole slaw.', 'price': 15000, 'options': [], 'recommended': False, 'order': 4}, {'product_id': 5, 'product_name': 'Viernes - Philadelphia steak sandwich', 'product_category': 'N0eOoycGSiKTYzGgn2y6', 'description': 'Certified Angus Beef ®. 130gr. acompañado de cebolla y pimentón verde salteados, bañado en queso cheddar fundido.', 'price': 15000, 'options': [], 'recommended': False, 'order': 5}, {'product_id': 6, 'product_name': 'Combo Burger', 'product_category': 'N0eOoycGSiKTYzGgn2y6', 'description': 'Escoge una de nuestras burgers de Angus Beef ® 150gr + french fries + Bretaña saborizada', 'price': 19900, 'options': [{'name': 'Escoge una burger entre:', 'multiple': False, 'required': False, 'variants': [{'name': 'La Gringa', 'price': 0.0}, {'name': 'Cheeseburger', 'price': 0.0}, {'name': 'Bacon Cheeseburger', 'price': 0.0}, {'name': 'Maple Bacon', 'price': 0.0}, {'name': 'Blue Mushroom', 'price': 0.0}]}], 'recommended': False, 'order': 6}, {'product_id': 7, 'product_name': 'Pulled-pork nachos', 'product_category': 'xZdFNIcpIq9vhlHtVGyA', 'description': 'totopos, carne desmechada en salsa BBQ, frijoles refritos, pico de gallo, queso fundido, guacamole y crema agria.', 'price': 23000, 'options': [], 'recommended': False, 'order': 1}, {'product_id': 8, 'product_name': 'Totopos', 'product_category': 'xZdFNIcpIq9vhlHtVGyA', 'description': 'totopos acompañados de pico de gallo, guacamole y crema agria.', 'price': 9900, 'options': [], 'recommended': False, 'order': 2}, {'product_id': 9, 'product_name': 'Fried cheese jalapeños', 'product_category': 'xZdFNIcpIq9vhlHtVGyA', 'description': 'jalapeños fritos rellenos de queso cheddar, cubiertos de queso cheddar fundido y cebollín.', 'price': 19000, 'options': [], 'recommended': False, 'order': 3}, {'product_id': 10, 'product_name': 'Bacon cheddar fries', 'product_category': 'xZdFNIcpIq9vhlHtVGyA', 'description': 'french fries, queso cheddar, tocineta y jalapeños.', 'price': 185000, 'options': [], 'recommended': False, 'order': 4}, {'product_id': 11, 'product_name': 'Potato skins 4 und', 'product_category': 'xZdFNIcpIq9vhlHtVGyA', 'description': 'cascos de papa rellenos de tocineta, crema agria, queso cheddar, queso doble crema y cebollín.', 'price': 16000, 'options': [], 'recommended': False, 'order': 5}, {'product_id': 12, 'product_name': 'Mozzarella fingers', 'product_category': 'xZdFNIcpIq9vhlHtVGyA', 'description': 'dedos de mozzarella cubiertos de salsa napolitana y albahaca.', 'price': 18000, 'options': [], 'recommended': False, 'order': 6}, {'product_id': 13, 'product_name': 'Tomato soup', 'product_category': 'xZdFNIcpIq9vhlHtVGyA', 'description': 'sopa de tomate con crema agria acompañada con sandwich a la plancha de queso.', 'price': 14000, 'options': [], 'recommended': False, 'order': 7}, {'product_id': 14, 'product_name': 'Onion rings', 'product_categor...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should look at the prices of the items to see which ones I can afford\n",
      "Action: json_spec_get_value\n",
      "Action Input: data[\"items\"][0][\"price\"]\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m15000\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should look at the other items to see which ones I can afford\n",
      "Action: json_spec_get_value\n",
      "Action Input: data[\"items\"][1][\"price\"]\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m15000\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should look at the other items to see which ones I can afford\n",
      "Action: json_spec_get_value\n",
      "Action Input: data[\"items\"][2][\"price\"]\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m15000\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should look at the other items to see which ones I can afford\n",
      "Action: json_spec_get_value\n",
      "Action Input: data[\"items\"][3][\"price\"]\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m15000\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should look at the other items to see which ones I can afford\n",
      "Action: json_spec_get_value\n",
      "Action Input: data[\"items\"][4][\"price\"]\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m15000\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Los platos que puedes comprar con 50000 pesos son Lunes - Creamy garlic chicken breast, Martes - Lemon butter chicken, Miercoles - Cajún-chicken sandwich, Jueves - Pulled-pork sandwich y Viernes - Philadelphia steak sandwich.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Los platos que puedes comprar con 50000 pesos son Lunes - Creamy garlic chicken breast, Martes - Lemon butter chicken, Miercoles - Cajún-chicken sandwich, Jueves - Pulled-pork sandwich y Viernes - Philadelphia steak sandwich.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import (\n",
    "    create_json_agent\n",
    ")\n",
    "from langchain.agents.agent_toolkits import JsonToolkit\n",
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.tools.json.tool import JsonSpec\n",
    "import json\n",
    "\n",
    "with open(\"./examples/menu.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "json_spec = JsonSpec(dict_=data, max_value_length=4000)\n",
    "json_toolkit = JsonToolkit(spec=json_spec)\n",
    "\n",
    "json_agent_executor = create_json_agent(\n",
    "    llm=OpenAI(temperature=0),\n",
    "    toolkit=json_toolkit,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "json_agent_executor.run(\"Solo tengo 50000 pesos, recomiendame algunos platos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to count the number of rows\n",
      "Action: python_repl_ast\n",
      "Action Input: df.shape[0]\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m891\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: There are 891 rows.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'There are 891 rows.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import create_csv_agent\n",
    "from langchain.llms import OpenAI\n",
    "agent = create_csv_agent(OpenAI(temperature=0), './examples/titanic.csv', verbose=True)\n",
    "agent.run(\"how many rows are there?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus\n",
    "- [Langchain for Golang!](https://github.com/tmc/langchaingo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "766abf25916efe62e65eea59f0dda71f02ee8cbab134d54d694e5619eba4b874"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
